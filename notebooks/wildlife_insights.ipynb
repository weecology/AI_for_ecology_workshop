{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data in Wild! Wildlife Insights Camera Trap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to download a sample dataset from Wildlife Insights, organize and prepare it for a simple machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13801 images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>deployment_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>location</th>\n",
       "      <th>is_blank</th>\n",
       "      <th>identified_by</th>\n",
       "      <th>wi_taxon_id</th>\n",
       "      <th>class</th>\n",
       "      <th>...</th>\n",
       "      <th>individual_id</th>\n",
       "      <th>number_of_objects</th>\n",
       "      <th>individual_animal_notes</th>\n",
       "      <th>behavior</th>\n",
       "      <th>highlighted</th>\n",
       "      <th>markings</th>\n",
       "      <th>cv_confidence</th>\n",
       "      <th>license</th>\n",
       "      <th>fuzzed</th>\n",
       "      <th>deployment_fuzzed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002681</td>\n",
       "      <td>235ae8b3-c867-47c3-bb14-014c693c5b46</td>\n",
       "      <td>5ee97c56-159b-4ad1-9120-a3c9aecd4ae8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02070366.JPG</td>\n",
       "      <td>https://app.wildlifeinsights.org/download/2007...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jessica Pacheco</td>\n",
       "      <td>d62cd43d-a519-4cd5-aef2-b76ae4bd16c1</td>\n",
       "      <td>Mammalia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC-BY</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002681</td>\n",
       "      <td>af1868f3-d47d-4035-9d8a-21b7dc39ea5a</td>\n",
       "      <td>b20cb762-7b69-4404-bd73-58ee46be75e1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12280095.JPG</td>\n",
       "      <td>https://app.wildlifeinsights.org/download/2007...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jessica Pacheco</td>\n",
       "      <td>d4a15eb4-1c47-4b90-8e3f-15fb51dc07e8</td>\n",
       "      <td>Mammalia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC-BY</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002681</td>\n",
       "      <td>f65b9a20-4e64-4ab9-b3fd-f717095f760f</td>\n",
       "      <td>6a03e7c0-ecf4-4daf-bfcb-4f9abefd86c8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12300191.JPG</td>\n",
       "      <td>https://app.wildlifeinsights.org/download/2007...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jessica Pacheco</td>\n",
       "      <td>c5ae795b-300f-4cc7-99f7-e2c2d2810a87</td>\n",
       "      <td>Mammalia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC-BY</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002681</td>\n",
       "      <td>af1868f3-d47d-4035-9d8a-21b7dc39ea5a</td>\n",
       "      <td>fe7b1810-3494-4405-ad2c-9445fe578cd5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12200074.JPG</td>\n",
       "      <td>https://app.wildlifeinsights.org/download/2007...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jessica Pacheco</td>\n",
       "      <td>d4a15eb4-1c47-4b90-8e3f-15fb51dc07e8</td>\n",
       "      <td>Mammalia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC-BY</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002681</td>\n",
       "      <td>f65b9a20-4e64-4ab9-b3fd-f717095f760f</td>\n",
       "      <td>ccc252ad-82e5-4375-8ea3-9829f4a6c845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12240117.JPG</td>\n",
       "      <td>https://app.wildlifeinsights.org/download/2007...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jessica Pacheco</td>\n",
       "      <td>c5ae795b-300f-4cc7-99f7-e2c2d2810a87</td>\n",
       "      <td>Mammalia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC-BY</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_id                         deployment_id  \\\n",
       "0     2002681  235ae8b3-c867-47c3-bb14-014c693c5b46   \n",
       "1     2002681  af1868f3-d47d-4035-9d8a-21b7dc39ea5a   \n",
       "2     2002681  f65b9a20-4e64-4ab9-b3fd-f717095f760f   \n",
       "3     2002681  af1868f3-d47d-4035-9d8a-21b7dc39ea5a   \n",
       "4     2002681  f65b9a20-4e64-4ab9-b3fd-f717095f760f   \n",
       "\n",
       "                               image_id  sequence_id      filename  \\\n",
       "0  5ee97c56-159b-4ad1-9120-a3c9aecd4ae8          NaN  02070366.JPG   \n",
       "1  b20cb762-7b69-4404-bd73-58ee46be75e1          NaN  12280095.JPG   \n",
       "2  6a03e7c0-ecf4-4daf-bfcb-4f9abefd86c8          NaN  12300191.JPG   \n",
       "3  fe7b1810-3494-4405-ad2c-9445fe578cd5          NaN  12200074.JPG   \n",
       "4  ccc252ad-82e5-4375-8ea3-9829f4a6c845          NaN  12240117.JPG   \n",
       "\n",
       "                                            location  is_blank  \\\n",
       "0  https://app.wildlifeinsights.org/download/2007...       NaN   \n",
       "1  https://app.wildlifeinsights.org/download/2007...       NaN   \n",
       "2  https://app.wildlifeinsights.org/download/2007...       NaN   \n",
       "3  https://app.wildlifeinsights.org/download/2007...       NaN   \n",
       "4  https://app.wildlifeinsights.org/download/2007...       NaN   \n",
       "\n",
       "     identified_by                           wi_taxon_id     class  ...  \\\n",
       "0  Jessica Pacheco  d62cd43d-a519-4cd5-aef2-b76ae4bd16c1  Mammalia  ...   \n",
       "1  Jessica Pacheco  d4a15eb4-1c47-4b90-8e3f-15fb51dc07e8  Mammalia  ...   \n",
       "2  Jessica Pacheco  c5ae795b-300f-4cc7-99f7-e2c2d2810a87  Mammalia  ...   \n",
       "3  Jessica Pacheco  d4a15eb4-1c47-4b90-8e3f-15fb51dc07e8  Mammalia  ...   \n",
       "4  Jessica Pacheco  c5ae795b-300f-4cc7-99f7-e2c2d2810a87  Mammalia  ...   \n",
       "\n",
       "  individual_id number_of_objects individual_animal_notes behavior  \\\n",
       "0           NaN                 1                     NaN      NaN   \n",
       "1           NaN                 1                     NaN      NaN   \n",
       "2           NaN                 1                     NaN      NaN   \n",
       "3           NaN                 1                     NaN      NaN   \n",
       "4           NaN                 1                     NaN      NaN   \n",
       "\n",
       "  highlighted  markings cv_confidence  license  fuzzed  deployment_fuzzed  \n",
       "0       False       NaN           NaN    CC-BY    True              False  \n",
       "1       False       NaN           NaN    CC-BY    True              False  \n",
       "2       False       NaN           NaN    CC-BY    True              False  \n",
       "3       False       NaN           NaN    CC-BY    True              False  \n",
       "4       False       NaN           NaN    CC-BY    True              False  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "annotations = pd.read_csv(\"/orange/ewhite/b.weinstein/CameraTraps/wildlife-insights_e658cfd5-62cf-4ef1-8c97-cb27cbfafb81_all-platform-data/images.csv\")\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "common_name\n",
       "Spectacled Bear               237\n",
       "Western Mountain Coati        161\n",
       "Northern Tiger Cat             43\n",
       "Dwarf Red Brocket              42\n",
       "Andean White-eared Opossum     41\n",
       "Black Agouti                   26\n",
       "Puma                           26\n",
       "Southern Tamandua              17\n",
       "Mammal                         12\n",
       "Tayra                          11\n",
       "Ocelot                          9\n",
       "Red-tailed Squirrel             7\n",
       "Sylvilagus Species              5\n",
       "White-browed Guan               2\n",
       "Common Opossum                  2\n",
       "Spix's Guan                     1\n",
       "No CV Result                    1\n",
       "Carnivorous Mammal              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[\"common_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 100%|██████████| 644/644 [00:58<00:00, 11.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Download images\n",
    "# Create the directory if it doesn't exist\n",
    "image_dir = \"wildlife_insights/\"\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "# Function to download images\n",
    "def download_images(annotations, image_dir):\n",
    "    image_list = annotations[\"filename\"].tolist()\n",
    "    for filename in tqdm(image_list, desc=\"Downloading images\"):\n",
    "        url = annotations.loc[annotations[\"filename\"] == filename, \"location\"].values[0]\n",
    "        file_path = os.path.join(image_dir, filename)\n",
    "        if not os.path.exists(file_path):  # Avoid re-downloading\n",
    "            try:\n",
    "                response = requests.get(url, stream=True)\n",
    "                if response.status_code == 200:\n",
    "                    with open(file_path, \"wb\") as f:\n",
    "                        for chunk in response.iter_content(1024):\n",
    "                            f.write(chunk)\n",
    "                else:\n",
    "                    print(f\"Failed to download {filename}: {response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {filename}: {e}\")\n",
    "\n",
    "# Download train and test images\n",
    "download_images(annotations, image_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m ocelot_image_filename = annotations[annotations[\u001b[33m\"\u001b[39m\u001b[33mcommon_name\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mOcelot\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m\"\u001b[39m].iloc[\u001b[32m0\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Full path to this notebook\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m notebook_path = os.path.abspath(\u001b[34;43m__file__\u001b[39;49m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Full path to the image\u001b[39;00m\n\u001b[32m      6\u001b[39m ocelot_image_path = os.path.join(notebook_path,image_dir,ocelot_image_filename)\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter for an image of an ocelot\n",
    "ocelot_image_filename = annotations[annotations[\"common_name\"] == \"Ocelot\"][\"filename\"].iloc[0]\n",
    "# Full path to this notebook\n",
    "notebook_path = os.path.abspath(__file__)\n",
    "\n",
    "# Full path to the image\n",
    "ocelot_image_path = os.path.join(notebook_path,image_dir,ocelot_image_filename)\n",
    "\n",
    "# Display the image\n",
    "if ocelot_image_path:\n",
    "    image = Image.open(ocelot_image_path)\n",
    "    image.show()\n",
    "else:\n",
    "    print(\"Ocelot image not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Terminology\n",
    "\n",
    "In the pytorch universe there are three key elements, datasets, dataloaders and models.\n",
    "\n",
    "Torch datasets are abstractions that handle data loading and preprocessing. They are typically subclasses of `torch.utils.data.Dataset` and define two main methods: `__len__` (returns the size of the dataset) and `__getitem__` (retrieves a data sample).\n",
    "\n",
    "Dataloaders, implemented via `torch.utils.data.DataLoader`, provide an iterable over a dataset, enabling efficient batching, shuffling, and parallel data loading.\n",
    "\n",
    "Models in PyTorch are defined as subclasses of `torch.nn.Module`. They encapsulate layers and define the forward pass of the network.\n",
    "\n",
    "PyTorch Lightning modules integrate these components by organizing the training, validation, and testing logic. A `LightningModule` defines methods like `training_step`, `validation_step`, and `test_step`, and connects datasets, dataloaders, and models into a cohesive workflow. This abstraction simplifies training loops and enables seamless integration with hardware accelerators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_classes:  Index(['Spectacled Bear', 'Western Mountain Coati', 'Northern Tiger Cat',\n",
      "       'Dwarf Red Brocket', 'Andean White-eared Opossum', 'Black Agouti',\n",
      "       'Puma', 'Southern Tamandua', 'Mammal', 'Tayra', 'Ocelot',\n",
      "       'Red-tailed Squirrel', 'Sylvilagus Species'],\n",
      "      dtype='object', name='common_name')\n",
      "Number of train images:  572\n",
      "Number of test images:  60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train test split\n",
    "# Filter out classes with less than 5 images\n",
    "class_counts = annotations[\"common_name\"].value_counts()\n",
    "valid_classes = class_counts[class_counts >= 5].index\n",
    "filtered_annotations = annotations[annotations[\"common_name\"].isin(valid_classes)]\n",
    "\n",
    "# Split images into train and test sets\n",
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "for common_name in valid_classes:\n",
    "    class_images = filtered_annotations[filtered_annotations[\"common_name\"] == common_name][\"filename\"].tolist()\n",
    "    if len(class_images) > 5:\n",
    "        train, test = train_test_split(class_images, test_size=5, random_state=42)\n",
    "        train_images.extend(train)\n",
    "        test_images.extend(test)\n",
    "\n",
    "print(\"valid_classes: \", valid_classes)\n",
    "print(\"Number of train images: \", len(train_images))\n",
    "print(\"Number of test images: \", len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class WildlifeDataset(Dataset):\n",
    "    def __init__(self, image_paths, annotations, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.annotations = annotations\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.annotations.loc[self.annotations['filename'] == img_path, 'common_name'].values[0]\n",
    "        \n",
    "        # Load the image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Example usage\n",
    "train_dataset = WildlifeDataset(train_images, filtered_annotations)\n",
    "test_dataset = WildlifeDataset(test_images, filtered_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '03090523.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m test_loader = DataLoader(test_dataset, batch_size=\u001b[32m32\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Example: Iterate through the train_loader\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBatch size: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mWildlifeDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     16\u001b[39m label = \u001b[38;5;28mself\u001b[39m.annotations.loc[\u001b[38;5;28mself\u001b[39m.annotations[\u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m] == img_path, \u001b[33m'\u001b[39m\u001b[33mcommon_name\u001b[39m\u001b[33m'\u001b[39m].values[\u001b[32m0\u001b[39m]\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Load the image\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m image = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m.convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Apply transformations if provided\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/PIL/Image.py:3465\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3462\u001b[39m     filename = os.fspath(fp)\n\u001b[32m   3464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3465\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3466\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3467\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '03090523.JPG'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Dataloader\n",
    "\n",
    "# Create DataLoaders for train and test datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Example: Iterate through the train_loader\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch size: {len(images)}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminología Clave de un Módulo de PyTorch Lightning\n",
    "\n",
    "### Terminología Clave\n",
    "1. **Datasets**: Abstracciones que manejan la carga y preprocesamiento de datos. Son subclases de `torch.utils.data.Dataset` y definen dos métodos principales: `__len__` (devuelve el tamaño del conjunto de datos) y `__getitem__` (recupera una muestra de datos).\n",
    "\n",
    "2. **Dataloaders**: Implementados mediante `torch.utils.data.DataLoader`, proporcionan un iterable sobre un conjunto de datos, permitiendo un batching eficiente, mezcla de datos y carga paralela.\n",
    "\n",
    "3. **Models**: Definidos como subclases de `torch.nn.Module`. Encapsulan capas y definen el paso hacia adelante (forward pass) de la red.\n",
    "\n",
    "4. **LightningModule**: Un módulo de PyTorch Lightning que organiza la lógica de entrenamiento, validación y prueba. Define métodos como `training_step`, `validation_step` y `test_step`, conectando datasets, dataloaders y modelos en un flujo de trabajo cohesivo. Esta abstracción simplifica los bucles de entrenamiento y permite una integración fluida con aceleradores de hardware.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/pytorch_lightning/__init__.py:25\u001b[39m\n\u001b[32m     22\u001b[39m     _logger.addHandler(logging.StreamHandler())\n\u001b[32m     23\u001b[39m     _logger.propagate = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m seed_everything  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m disable_possible_user_warnings  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callback  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/lightning_fabric/__init__.py:35\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys.platform == \u001b[33m\"\u001b[39m\u001b[33mwin32\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     32\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mUSE_LIBUV\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Fabric  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m seed_everything  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m disable_possible_user_warnings  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/lightning_fabric/fabric.py:40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccelerators\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccelerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _PLUGIN_INPUT, _PRECISION_INPUT, _Connector, _is_using_cli\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloggers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Logger\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplugins\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Precision  \u001b[38;5;66;03m# avoid circular imports: # isort: split\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstrategies\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     43\u001b[39m     DataParallelStrategy,\n\u001b[32m     44\u001b[39m     DeepSpeedStrategy,\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     XLAStrategy,\n\u001b[32m     49\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/lightning_fabric/loggers/__init__.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloggers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcsv_logs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CSVLogger  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloggers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Logger  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloggers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensorboard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorBoardLogger  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/lightning_fabric/loggers/tensorboard.py:31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrank_zero\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rank_zero_only, rank_zero_warn\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _PATH\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning_fabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrappers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _unwrap_objects\n\u001b[32m     33\u001b[39m _TENSORBOARD_AVAILABLE = RequirementCache(\u001b[33m\"\u001b[39m\u001b[33mtensorboard\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m _TENSORBOARDX_AVAILABLE = RequirementCache(\u001b[33m\"\u001b[39m\u001b[33mtensorboardX\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/lightning_fabric/wrappers.py:33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn \u001b[38;5;28;01mas\u001b[39;00m nn\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OptimizedModule\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _IncompatibleKeys\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_dynamo/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyScalarRestartAnalysis\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracing, TracingContext\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, exc, logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging, trace_rules, variables\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     32\u001b[39m     get_indexof,\n\u001b[32m     33\u001b[39m     JUMP_OPNAMES,\n\u001b[32m     34\u001b[39m     livevars_analysis,\n\u001b[32m     35\u001b[39m     propagate_line_nums,\n\u001b[32m     36\u001b[39m )\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     38\u001b[39m     cleaned_instructions,\n\u001b[32m     39\u001b[39m     create_call_function,\n\u001b[32m   (...)\u001b[39m\u001b[32m     46\u001b[39m     unique_id,\n\u001b[32m     47\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py:46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresume_execution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     47\u001b[39m     BuiltinVariable,\n\u001b[32m     48\u001b[39m     FunctionalCallVariable,\n\u001b[32m     49\u001b[39m     FunctorchHigherOrderVariable,\n\u001b[32m     50\u001b[39m     NestedUserFunctionVariable,\n\u001b[32m     51\u001b[39m     PolyfilledFunctionVariable,\n\u001b[32m     52\u001b[39m     SkipFunctionVariable,\n\u001b[32m     53\u001b[39m     TorchInGraphFunctionVariable,\n\u001b[32m     54\u001b[39m     UserFunctionVariable,\n\u001b[32m     55\u001b[39m     UserMethodVariable,\n\u001b[32m     56\u001b[39m )\n\u001b[32m     59\u001b[39m np: Optional[types.ModuleType] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_dynamo/variables/__init__.py:109\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msdpa\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SDPAParamsVariable\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    101\u001b[39m     DataPtrVariable,\n\u001b[32m    102\u001b[39m     FakeItemVariable,\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m     UntypedStorageVariable,\n\u001b[32m    108\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TorchCtxManagerClassVariable, TorchInGraphFunctionVariable\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01muser_defined\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    111\u001b[39m     MutableMappingVariable,\n\u001b[32m    112\u001b[39m     RemovableHandleVariable,\n\u001b[32m    113\u001b[39m     UserDefinedClassVariable,\n\u001b[32m    114\u001b[39m     UserDefinedObjectVariable,\n\u001b[32m    115\u001b[39m )\n\u001b[32m    118\u001b[39m __all__ = [\n\u001b[32m    119\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAutogradFunctionContextVariable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    120\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAutogradFunctionVariable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    184\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWithExitFunctionVariable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    185\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_dynamo/variables/torch.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_traceable_wrapper_subclass_type\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, polyfills, variables\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodegen\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyCodegen\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcreate_parameter_op\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     can_convert_to_tracable_parameter,\n\u001b[32m     22\u001b[39m     new_parameter_placeholder,\n\u001b[32m     23\u001b[39m     tracable_create_parameter,\n\u001b[32m     24\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_registered_device_interfaces\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_dynamo/codegen.py:35\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NNModuleVariable\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     30\u001b[39m     NumpyNdarrayVariable,\n\u001b[32m     31\u001b[39m     SymNodeVariable,\n\u001b[32m     32\u001b[39m     TensorVariable,\n\u001b[32m     33\u001b[39m     UnspecializedPythonVariable,\n\u001b[32m     34\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtorch_function\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorWithTFOverrideVariable\n\u001b[32m     38\u001b[39m \u001b[38;5;129m@dataclasses\u001b[39m.dataclass\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mGraphOutputEntry\u001b[39;00m:\n\u001b[32m     40\u001b[39m     index: \u001b[38;5;28mint\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_dynamo/variables/torch_function.py:185\u001b[39m\n\u001b[32m    181\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m most_recent_func != BUILTIN_TO_TENSOR_FN_MAP[op]:\n\u001b[32m    182\u001b[39m                     BUILTIN_TO_TENSOR_RFN_MAP[op] = most_recent_func\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[43mpopulate_builtin_to_tensor_fn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m banned_attrs = [\n\u001b[32m    188\u001b[39m     fn.\u001b[34m__self__\u001b[39m.\u001b[34m__name__\u001b[39m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions()\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_tensor_base_attr_getter(fn)\n\u001b[32m    191\u001b[39m ]\n\u001b[32m    194\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_prev_stack_var_name\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_dynamo/variables/torch_function.py:179\u001b[39m, in \u001b[36mpopulate_builtin_to_tensor_fn_map\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m rskips:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43msetup_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m most_recent_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m most_recent_func != BUILTIN_TO_TENSOR_FN_MAP[op]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_dynamo/variables/torch_function.py:167\u001b[39m, in \u001b[36mpopulate_builtin_to_tensor_fn_map.<locals>.<lambda>\u001b[39m\u001b[34m(o)\u001b[39m\n\u001b[32m    162\u001b[39m         BUILTIN_TO_TENSOR_FN_MAP[op] = most_recent_func\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# gather the reverse functions\u001b[39;00m\n\u001b[32m    165\u001b[39m rsetups_and_oplists = [\n\u001b[32m    166\u001b[39m     (\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m o: \u001b[43mo\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp1\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    168\u001b[39m         bin_ops,\n\u001b[32m    169\u001b[39m     ),  \u001b[38;5;66;03m# Get r* ops, (ex. __sub__(int, Tensor) -> __rsub__(Tensor, int))\u001b[39;00m\n\u001b[32m    170\u001b[39m     (\u001b[38;5;28;01mlambda\u001b[39;00m o: o(\u001b[32m1\u001b[39m, inp1_int), bin_int_ops),\n\u001b[32m    171\u001b[39m     (\u001b[38;5;28;01mlambda\u001b[39;00m o: o(\u001b[32m0\u001b[39m, inp0_int), tensor_and_int_ops),\n\u001b[32m    172\u001b[39m ]\n\u001b[32m    174\u001b[39m rskips = {operator.matmul, operator.imatmul, operator.getitem}\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m setup_fn, op_list \u001b[38;5;129;01min\u001b[39;00m rsetups_and_oplists:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_tensor.py:38\u001b[39m, in \u001b[36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f(*args, **kwargs)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/overrides.py:1720\u001b[39m, in \u001b[36mhandle_torch_function\u001b[39m\u001b[34m(public_api, relevant_args, *args, **kwargs)\u001b[39m\n\u001b[32m   1716\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[32m   1717\u001b[39m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[32m   1718\u001b[39m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[32m   1719\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[32m-> \u001b[39m\u001b[32m1720\u001b[39m         result = \u001b[43mmode\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1721\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[32m   1722\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_dynamo/variables/torch_function.py:144\u001b[39m, in \u001b[36mpopulate_builtin_to_tensor_fn_map.<locals>.GetMethodMode.__torch_function__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mnonlocal\u001b[39;00m most_recent_func\n\u001b[32m    143\u001b[39m most_recent_func = func\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_tensor.py:39\u001b[39m, in \u001b[36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/blue/ewhite/b.weinstein/miniconda3/envs/megadetector/lib/python3.11/site-packages/torch/_tensor.py:1091\u001b[39m, in \u001b[36mTensor.__rmod__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   1089\u001b[39m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__rmod__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremainder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "class ResNetClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        # Load a pre-trained ResNet model\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        # Replace the final fully connected layer to match the number of classes\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "# Instantiate the model\n",
    "num_classes = len(valid_classes)\n",
    "model = ResNetClassifier(num_classes)\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "\n",
    "# Fit the model\n",
    "trainer.fit(model, train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megadetector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
