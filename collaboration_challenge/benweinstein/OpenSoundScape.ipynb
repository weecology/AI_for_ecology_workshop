{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring a new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important steps in ecological machine learning is defining the problem and understanding the data. In this notebook I look at general strategies for successful machine learning. \n",
    "\n",
    "1. What does the data look like?\n",
    "2. What existing models can help?\n",
    "3. How can we fine-tune existing models to customize to our data?\n",
    "4. How better clean the data to reduce the noise and focus on the key elements?\n",
    "5. How can we organize and track train and test splits to increase predictive accuracy?\n",
    "\n",
    "To highlight these concepts, intentionally chose a dataset I have no experience with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape.ml.cnn import load_model\n",
    "from opensoundscape import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de bibliotecas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analizar_distribucion_especies(train_df):\n",
    "    \"\"\"\n",
    "    Analiza la distribución de especies en el conjunto de datos.\n",
    "    Args:\n",
    "        train_df (DataFrame): DataFrame de entrenamiento\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Análisis de Distribución de Especies ===\")\n",
    "    \n",
    "    # Análisis de distribución de especies\n",
    "    species_counts = train_df['primary_label'].value_counts()\n",
    "    \n",
    "    # Visualización de las 20 especies más comunes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    species_counts.head(20).plot(kind='bar')\n",
    "    plt.title('Top 20 Especies más Comunes')\n",
    "    plt.xlabel('Especie')\n",
    "    plt.ylabel('Cantidad de Registros')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    print(f\"\\nTotal de especies únicas: {len(species_counts)}\")\n",
    "    print(f\"Especie más común: {species_counts.index[0]} ({species_counts.iloc[0]} registros)\")\n",
    "    print(f\"Especie menos común: {species_counts.index[-1]} ({species_counts.iloc[-1]} registros)\")\n",
    "\n",
    "    # Visualización de las 20 especies más comunes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    species_counts.plot(kind='bar')\n",
    "    plt.xlabel('Especie')\n",
    "    plt.ylabel('Cantidad de Registros')\n",
    "\n",
    "def cargar_datos():\n",
    "    \"\"\"\n",
    "    Carga los archivos principales del conjunto de datos.\n",
    "    Returns:\n",
    "        tuple: DataFrames de entrenamiento, taxonomía y muestra\n",
    "    \"\"\"\n",
    "    print(\"Cargando datos...\")\n",
    "    \n",
    "    # Carga de archivos principales\n",
    "    train_df = pd.read_csv(\"../birdclef-2025/train.csv\")\n",
    "    taxonomy_df = pd.read_csv(\"../birdclef-2025/taxonomy.csv\")\n",
    "    sample_submission = pd.read_csv(\"../birdclef-2025/sample_submission.csv\")\n",
    "    \n",
    "    # Carga de metadatos de ubicación\n",
    "    with open(\"../birdclef-2025/recording_location.txt\", \"r\") as f:\n",
    "        recording_location = f.read()\n",
    "    \n",
    "    print(f\"Datos de entrenamiento: {train_df.shape}\")\n",
    "    print(f\"Datos taxonómicos: {taxonomy_df.shape}\")\n",
    "    print(f\"Archivo de muestra: {sample_submission.shape}\")\n",
    "    \n",
    "    return train_df, taxonomy_df, sample_submission, recording_location\n",
    "\n",
    "train_df, taxonomy_df, sample_submission, recording_location = cargar_datos()\n",
    "\n",
    "analizar_distribucion_especies(train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model\n",
    "\n",
    "https://github.com/kitzeslab/bioacoustics-model-zoo?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opensoundscape and BirdCLEF\n",
    "import bioacoustics_model_zoo as bmz\n",
    "\n",
    "# list available models from the model zoo\n",
    "bmz.utils.list_models()\n",
    "\n",
    "# Load the model\n",
    "m=bmz.BirdSetEfficientNetB1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose a fairly common bird species with a distinctive call.\n",
    "\n",
    "https://ebird.org/species/crebob1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crested_Bobwhite = train_df[train_df.common_name == \"Crested Bobwhite\"]\n",
    "Crested_Bobwhite.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio\n",
    "file_path = \"../birdclef-2025/train_audio/crebob1/XC148253.ogg\"\n",
    "audio = Audio.from_file(file_path)\n",
    "fft_spectrum, frequencies = audio.spectrum()\n",
    "\n",
    "# Plot settings\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plot\n",
    "plt.plot(frequencies,fft_spectrum)\n",
    "plt.ylabel('Fast Fourier Transform (V**2/Hz)')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.show()\n",
    "\n",
    "# Low pass filter\n",
    "clean_audio = audio.reduce_noise().highpass(1000, order=8).lowpass(5000, order=8).normalize()\n",
    "fft_spectrum, frequencies = clean_audio.spectrum()\n",
    "\n",
    "# Plot\n",
    "plt.plot(frequencies,fft_spectrum)\n",
    "plt.ylabel('Fast Fourier Transform (V**2/Hz)')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.show()\n",
    "clean_audio.show_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape import Audio, Spectrogram\n",
    "spectrogram_object = Spectrogram.from_audio(clean_audio)\n",
    "spectrogram_object.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict use pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_audio.save(\"clean_audio.wav\")\n",
    "scores = m.predict(\"clean_audio.wav\", activation_layer=\"sigmoid\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape.metrics import predict_multi_target_labels\n",
    "predicted_labels = predict_multi_target_labels(scores, threshold=0.5)\n",
    "predicted_labels\n",
    "# count the number of detections for each species\n",
    "detection_counts = predicted_labels.sum(0)\n",
    "detections = detection_counts[detection_counts > 0]\n",
    "\n",
    "print(detections)\n",
    "\n",
    "# Matching taxonomy\n",
    "taxonomy_df.loc[taxonomy_df.primary_label.isin(detections.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lessons learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data formats and installation are the hardest part of getting started. Most projects fail here.\n",
    "2. Taxonomy is a persistant challenge.\n",
    "3. Generalization across time and space limits open source models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "1. Aligning taxonomies of existing models and our dataset\n",
    "2. Intelligent preprocessing to focus on the target species. \n",
    "3. Training our own classifier starting from this existing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is one overarching lesson from the last 10 years of ecological machine learning research, its that starting from existing backbone is the most common strategy for success. Data from a suprisingly wide array of sources can be useful. Let's retrain this backbone with our classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at this model statement, we can see we need embeddings of size 1280 and strip off the top layer. We can keep the bottom layers by freezing the backbone. Following the README.md https://github.com/kitzeslab/bioacoustics-model-zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split with 1 random sample per class for test\n",
    "test_df = train_df.groupby('primary_label').apply(lambda x: x.sample(n=1)).reset_index(drop=True)\n",
    "train_df = train_df[~train_df.index.isin(test_df.index)]\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "labels = train_df.primary_label.unique()\n",
    "m.change_classes(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not clear how train_df should be formatted\n",
    "\n",
    "# Create a mini dataset for testing, one train sample for each species\n",
    "train_df = train_df.groupby('primary_label').apply(lambda x: x.sample(n=1)).reset_index(drop=True)\n",
    "\n",
    "formatted_train_df = pd.get_dummies(train_df[[\"filename\", \"primary_label\"]].set_index(\"filename\")[\"primary_label\"]) * 1\n",
    "formatted_test_df = pd.get_dummies(test_df[[\"filename\", \"primary_label\"]].set_index(\"filename\")[\"primary_label\"]) * 1\n",
    "\n",
    "formatted_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape.ml.shallow_classifier import MLPClassifier, quick_fit, fit_classifier_on_embeddings\n",
    "import torch\n",
    "\n",
    "clf = clf = MLPClassifier(\n",
    "    input_size=1280, output_size=formatted_train_df.shape[1], hidden_layer_sizes=()\n",
    ")\n",
    "\n",
    "emb_train, label_train, emb_val, label_val = fit_classifier_on_embeddings(\n",
    "    embedding_model=m,\n",
    "    classifier_model=clf,\n",
    "    train_df=formatted_train_df,\n",
    "    validation_df=formatted_test_df,\n",
    "    steps=1,\n",
    "    embedding_batch_size=128,\n",
    "    embedding_num_workers=2,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megadetector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
